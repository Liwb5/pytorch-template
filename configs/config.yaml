# 0402: max_selected number
# 0403: using recall score instead of f-score in ROUGE-L when calculating reward
# 0404: preprocess data in order to remove sentence which length is shorter than 2
task_name: train.taskname.v0_0.0406
device: 0
log_level: info 
use_summaryWriter: False
seed: 1667
loss: BCELoss 
metrics: none

optimizer: 
    generator:
        type: Adam
        args:
            lr: 0.0001
            weight_decay: 0.000001

    discriminator:
        type: Adam
        args:
            lr: 0.0001
            weight_decay: 0.000001
    
trainer:
    type: Trainer
    args:
        epochs: 30
        save_period: 1
        print_loss_every: 20                   # print train loss every [num] batches, related to the batch size
        print_token_every: 1000000000             # print training tokens to see the result. print every [num] batches 
        print_val_token_every: 500000000         # print val tokens to see the result. print every [num] batches 
        do_validation: False
        save_dir: checkpoints/
        log_dir: logs/
        output_dir: outputs/

dataloader:
    type: AnimeDataset
    args:
        train_data: ./data/anime/
        # val_data: ./data/cnn-dailymail/finished_files3/val.json
        # test_data: ./data/cnn-dailymail/finished_files3/test.json
        batch_size: 20
        shuffle: True
        val_data_quota: -1
        data_quota: -1


model: 
    type: DCGAN
    args: 
        generator:
            input_dim: 300
            channels: [512, 256, 128, 64, 3]
            kernel_size: 4
            stride: 2
            padding: 1

        discriminator:
            channels: [3, 64, 128, 256, 512]
            kernel_size: 4
            stride: 2
            padding: 1

